{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lng\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Load dataset\n",
    "dataset = np.load(\"./mnist_dataset.npz\")\n",
    "#training set\n",
    "Xtr = dataset[\"Xtr\"]\n",
    "#training noisy label\n",
    "Str = dataset[\"Str\"]\n",
    "#test set\n",
    "Xts = dataset[\"Xts\"]\n",
    "#test noisy label\n",
    "Yts = dataset[\"Yts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate the weight of importance reweighting\n",
    "#prob is probibilty, rho0 and rho1 are flip rate\n",
    "def estimateBeta(S,prob,rho0,rho1):\n",
    "    n = len(S)\n",
    "    beta = np.zeros((n,1))\n",
    "    for i in range(n):\n",
    "        if S[i]==1:\n",
    "            beta[i] = (prob[i][1]-rho0)/((1-rho0-rho1)*prob[i][1]+1e-5)\n",
    "        else:\n",
    "            beta[i] = (prob[i][0]-rho1)/((1-rho0-rho1)*(prob[i][0])+1e-5)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the accuracy\n",
    "def computeAccuracy(Y,pred_Y):\n",
    "    acc = 0.0\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == pred_Y[i]:\n",
    "            acc += 1.0\n",
    "    return acc/len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#randomly split the data and get 80% of trainning samples\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of LR model trained on clean data is 0.7620\n"
     ]
    }
   ],
   "source": [
    "# implement LogisticRegression without label noise methods\n",
    "clf = LogisticRegression().fit(X_train, y_train.flatten())\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_\n",
    "#predict the result\n",
    "pred_Y = clf.predict(Xts)\n",
    "accTrue = computeAccuracy(Yts,pred_Y)\n",
    "print('The accuracy of LR model trained on clean data is %.4f'%accTrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.7620 0\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 1\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 2\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 3\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 4\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 5\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 6\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 7\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 8\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#split the train data, select 80& as samples\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c parameters in LR\n",
    "accuarcy_c=[]\n",
    "C = [0.001,0.01,0.1,1, 10, 100,1000]\n",
    "for i in range(10):\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    clf = LogisticRegression().fit(X_train, y_train.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_c.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### classify image without using label noise method\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_c=[]\n",
    "C = [0.001,0.01,0.1,1, 10, 100,1000]\n",
    "for c in C:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    clf = LogisticRegression(C=c).fit(X_train, y_train.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_c.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.7880 10\n",
      "The accuracy of IRLR model trained on noisy data is 0.7670 50\n",
      "The accuracy of IRLR model trained on noisy data is 0.7635 80\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 100\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 110\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 120\n",
      "The accuracy of IRLR model trained on noisy data is 0.7620 150\n"
     ]
    }
   ],
   "source": [
    "#unbaised estimator\n",
    "# max_iter : int, default: 100\n",
    "#Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "from sklearn.model_selection import train_test_split \n",
    "#tuning c in LR\n",
    "accuarcy_max_iter =[]\n",
    "max_iter  = [10,50,80,100,110,120,150]\n",
    "for i in max_iter:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)      \n",
    "    clf = LogisticRegression(max_iter =i).fit(X_train, y_train.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_max_iter.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the flip rate \n",
    "rho1 = 0.4\n",
    "rho0 = 0.2\n",
    "probS = clf.predict_proba(X_train)\n",
    "#get the weight of importance reweighting\n",
    "weights = estimateBeta(y_train, probS, rho0, rho1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9080\n"
     ]
    }
   ],
   "source": [
    "#use importance reweighting to classifiy the results\n",
    "clf = LogisticRegression().fit(X_train, y_train.flatten(), weights.flatten())\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_\n",
    "\n",
    "pred_Y = clf.predict(Xts)\n",
    "acc = computeAccuracy(Yts,pred_Y)\n",
    "print('The accuracy of IRLR model trained on noisy data is %.4f'%acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#parameter tuning\n",
    "rf = LogisticRegression() \n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "print(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9090 0.001\n",
      "The accuracy of IRLR model trained on noisy data is 0.9065 0.01\n",
      "The accuracy of IRLR model trained on noisy data is 0.9095 0.1\n",
      "The accuracy of IRLR model trained on noisy data is 0.9080 1\n",
      "The accuracy of IRLR model trained on noisy data is 0.9040 10\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 100\n",
      "The accuracy of IRLR model trained on noisy data is 0.9070 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_c=[]\n",
    "C = [0.001,0.01,0.1,1, 10, 100,1000]\n",
    "for c in C:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(C=c).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_c.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_penalty=[]\n",
    "penalty = [\"l1\",\"l2\"]\n",
    "for i in penalty:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(penalty=i).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_c.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.8915 10\n",
      "The accuracy of IRLR model trained on noisy data is 0.9080 50\n",
      "The accuracy of IRLR model trained on noisy data is 0.8985 80\n",
      "The accuracy of IRLR model trained on noisy data is 0.9080 100\n",
      "The accuracy of IRLR model trained on noisy data is 0.9085 120\n",
      "The accuracy of IRLR model trained on noisy data is 0.9030 150\n"
     ]
    }
   ],
   "source": [
    "# max_iter : int, default: 100\n",
    "#Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_max_iter =[]\n",
    "max_iter  = [10,50,80,100,110,120,150]\n",
    "for i in max_iter:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(max_iter =i).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_max_iter.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9080 160\n",
      "The accuracy of IRLR model trained on noisy data is 0.9080 170\n",
      "The accuracy of IRLR model trained on noisy data is 0.9065 180\n",
      "The accuracy of IRLR model trained on noisy data is 0.9085 190\n",
      "The accuracy of IRLR model trained on noisy data is 0.9090 200\n"
     ]
    }
   ],
   "source": [
    "# max_iter : int, default: 100\n",
    "#Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_max_iter =[]\n",
    "max_iter  = [160,170,180,190,200]\n",
    "for i in max_iter:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    weights = estimateBeta(y_train, probS, rho0, rho1)\n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(max_iter =i).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_max_iter.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9090 110\n",
      "The accuracy of IRLR model trained on noisy data is 0.9070 105\n",
      "The accuracy of IRLR model trained on noisy data is 0.9090 110\n",
      "The accuracy of IRLR model trained on noisy data is 0.9085 120\n",
      "The accuracy of IRLR model trained on noisy data is 0.9070 130\n",
      "The accuracy of IRLR model trained on noisy data is 0.9070 140\n",
      "The accuracy of IRLR model trained on noisy data is 0.9030 150\n",
      "The accuracy of IRLR model trained on noisy data is 0.9080 160\n"
     ]
    }
   ],
   "source": [
    "# max_iter : int, default: 100\n",
    "#Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_max_iter =[]\n",
    "max_iter  = [110,105,110,120,130,140,150,160]\n",
    "for i in max_iter:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(max_iter =i).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_max_iter.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9105 0\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 1\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 2\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 3\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 4\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 5\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 6\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 7\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 8\n",
      "The accuracy of IRLR model trained on noisy data is 0.9105 9\n"
     ]
    }
   ],
   "source": [
    "# ten-folds for the best combination\n",
    "accuarcy_Best=[]\n",
    "for i in range(10):\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    #X_train,y_train= RandomData(Xtr,Str)\n",
    "    clf = LogisticRegression(C=100,max_iter =100).fit(X_train, y_train, weights.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_Best.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guoguo/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "#estimate the flip rate\n",
    "probS = clf.predict_proba(X_v)\n",
    "x = 0\n",
    "#the correct number of labels 0\n",
    "correct_0 = 0\n",
    "#the correct number of labels 1\n",
    "correct_1 =0\n",
    "#the wrong number of labels 0\n",
    "wrong_0 = 0\n",
    "#the wrong number of labels 1\n",
    "wrong_1 = 0\n",
    "for L0,L1 in probS:\n",
    "    #print(L0,L1)\n",
    "    label = y_v[x][0]\n",
    "    #if label is 0, compare the problilty of estimated as 0\n",
    "    if label == 0:\n",
    "        if L1 >= 0.5:\n",
    "            wrong_0+=1\n",
    "        else:\n",
    "            correct_0+=1\n",
    "    #if label is 1, compare the problilty of estimated as 1\n",
    "    if label == 1:\n",
    "        if L0 >= 0.5:\n",
    "            wrong_1+=1\n",
    "        else:\n",
    "            correct_1+=1\n",
    "    x +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771 585 437 207\n",
      "p0: 0.2116564417177914\n",
      "p1: 0.42759295499021527\n"
     ]
    }
   ],
   "source": [
    "# p0(S = 1|Y = 0) = 0.2  p1(S=0|Y =1)=0.4\n",
    "print(correct_0,correct_1,wrong_0,wrong_1)\n",
    "print(\"p0:\",wrong_1/(correct_0+wrong_1))\n",
    "print(\"p1:\",wrong_0/(correct_1+wrong_0))\n",
    "#print(wrong_0/(correct_1+wrong_0),wrong_1/(correct_0+wrong_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate the weight of unbiased estimator\n",
    "def eval_weight(y, rho0, rho1):   \n",
    "    rho_y = y * rho1 + (1 - y) * rho0 # \\rho_{y}\n",
    "    rho_y_flip = y * rho0 + (1 - y) * rho1 # \\rho_{-y}\n",
    "    w = (1 - rho_y_flip) / (1 - rho1 - rho0)\n",
    "    w_flip = - rho_y / (1 - rho1 - rho0)\n",
    "    return w, w_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 784) (16000, 1)\n",
      "(16000, 1)\n"
     ]
    }
   ],
   "source": [
    "rho1 = 0.4\n",
    "rho0 = 0.2  \n",
    "#split data\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)\n",
    "#get the matrix of train and label\n",
    "Xtr_hat = np.concatenate((X_train, X_train), axis=0) # [data; data].\n",
    "Str_hat = np.concatenate((y_train, 1-y_train), axis=0) # [label; flipped-label].\n",
    "print(Xtr_hat.shape, Str_hat.shape) \n",
    "\n",
    "W, W_flip = eval_weight(y_train, rho0, rho1)\n",
    "W_hat = np.concatenate((W, W_flip), axis=0)\n",
    "print(W_hat.shape)\n",
    "\n",
    "# train LR classifier with unbiased estimator.\n",
    "clf = LogisticRegression().fit(Xtr_hat, Str_hat.flatten(), W_hat.flatten())\n",
    "w = clf.coef_[0]\n",
    "b = clf.intercept_\n",
    "pred_Y = clf.predict(Xts)\n",
    "acc = computeAccuracy(Yts,pred_Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.8855 10\n",
      "The accuracy of IRLR model trained on noisy data is 0.8995 50\n",
      "The accuracy of IRLR model trained on noisy data is 0.9025 80\n",
      "The accuracy of IRLR model trained on noisy data is 0.9005 100\n",
      "The accuracy of IRLR model trained on noisy data is 0.9015 110\n",
      "The accuracy of IRLR model trained on noisy data is 0.8965 120\n",
      "The accuracy of IRLR model trained on noisy data is 0.9015 150\n"
     ]
    }
   ],
   "source": [
    "#unbaised estimator methods with tuning the c parameter from 10 to 150\n",
    "# max_iter : int, default: 100 \n",
    "#Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n",
    "from sklearn.model_selection import train_test_split\n",
    "#tuning c in LR\n",
    "accuarcy_max_iter =[]\n",
    "max_iter  = [10,50,80,100,110,120,150]\n",
    "for i in max_iter:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    Xtr_hat = np.concatenate((X_train, X_train), axis=0) # [data; data].\n",
    "    Str_hat = np.concatenate((y_train, 1-y_train), axis=0) # [label; flipped-label].\n",
    "    W, W_flip = eval_weight(y_train, rho0, rho1)\n",
    "    W_hat = np.concatenate((W, W_flip), axis=0)\n",
    "    \n",
    "    clf = LogisticRegression(max_iter =i).fit(Xtr_hat, Str_hat.flatten(), W_hat.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_max_iter.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of IRLR model trained on noisy data is 0.9060 160\n",
      "The accuracy of IRLR model trained on noisy data is 0.9090 170\n",
      "The accuracy of IRLR model trained on noisy data is 0.9045 180\n",
      "The accuracy of IRLR model trained on noisy data is 0.9025 190\n",
      "The accuracy of IRLR model trained on noisy data is 0.9045 200\n"
     ]
    }
   ],
   "source": [
    "#unbaised estimator methods with tuning the c parameter from 160 to 200\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "#tuning c in LR\n",
    "accuarcy_c=[]\n",
    "C = [160,170,180,190,200]\n",
    "for c in C:\n",
    "    X_train, X_v, y_train, y_v = train_test_split(Xtr, Str, test_size=0.2, random_state=0,shuffle=True)  \n",
    "    Xtr_hat = np.concatenate((X_train, X_train), axis=0) # [data; data].\n",
    "    Str_hat = np.concatenate((y_train, 1-y_train), axis=0) # [label; flipped-label].\n",
    "    W, W_flip = eval_weight(y_train, rho0, rho1)\n",
    "    W_hat = np.concatenate((W, W_flip), axis=0)\n",
    "    \n",
    "    clf = LogisticRegression(C=c).fit(Xtr_hat, Str_hat.flatten(), W_hat.flatten())\n",
    "    pred_Y = clf.predict(Xts)\n",
    "    acc = computeAccuracy(Yts,pred_Y)\n",
    "    accuarcy_c.append(acc)\n",
    "    print('The accuracy of IRLR model trained on noisy data is %.4f'%acc,c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
